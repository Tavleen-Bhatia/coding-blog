<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Adeep%20learning%26id_list%3D%26start%3D0%26max_results%3D5" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:deep learning&amp;id_list=&amp;start=0&amp;max_results=5</title>
  <id>http://arxiv.org/api/o6m5I8YDMO+W1ZfiBhSOoh9xyHo</id>
  <updated>2025-05-14T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">424655</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">5</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2505.08788v1</id>
    <updated>2025-05-13T17:59:47Z</updated>
    <published>2025-05-13T17:59:47Z</published>
    <title>GNN-based Precoder Design and Fine-tuning for Cell-free Massive MIMO
  with Real-world CSI</title>
    <summary>  Cell-free massive MIMO (CF-mMIMO) has emerged as a promising paradigm for
delivering uniformly high-quality coverage in future wireless networks. To
address the inherent challenges of precoding in such distributed systems,
recent studies have explored the use of graph neural network (GNN)-based
methods, using their powerful representation capabilities. However, these
approaches have predominantly been trained and validated on synthetic datasets,
leaving their generalizability to real-world propagation environments largely
unverified. In this work, we initially pre-train the GNN using simulated
channel state information (CSI) data, which incorporates standard propagation
models and small-scale Rayleigh fading. Subsequently, we finetune the model on
real-world CSI measurements collected from a physical testbed equipped with
distributed access points (APs). To balance the retention of pre-trained
features with adaptation to real-world conditions, we adopt a layer-freezing
strategy during fine-tuning, wherein several GNN layers are frozen and only the
later layers remain trainable. Numerical results demonstrate that the
fine-tuned GNN significantly outperforms the pre-trained model, achieving an
approximate 8.2 bits per channel use gain at 20 dB signal-to-noise ratio (SNR),
corresponding to a 15.7 % improvement. These findings highlight the critical
role of transfer learning and underscore the potential of GNN-based precoding
techniques to effectively generalize from synthetic to real-world wireless
environments.
</summary>
    <author>
      <name>Tianzheng Miao</name>
    </author>
    <author>
      <name>Thomas Feys</name>
    </author>
    <author>
      <name>Gilles Callebaut</name>
    </author>
    <author>
      <name>Jarne Van Mulders</name>
    </author>
    <author>
      <name>Emanuele Peschiera</name>
    </author>
    <author>
      <name>Md Arifur Rahman</name>
    </author>
    <author>
      <name>Fran√ßois Rottenberg</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">6 pages, 7 figures, conference</arxiv:comment>
    <link href="http://arxiv.org/abs/2505.08788v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.08788v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="94A15 (Primary), 68T05 (Secondary)" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.08787v1</id>
    <updated>2025-05-13T17:59:22Z</updated>
    <published>2025-05-13T17:59:22Z</published>
    <title>UniSkill: Imitating Human Videos via Cross-Embodiment Skill
  Representations</title>
    <summary>  Mimicry is a fundamental learning mechanism in humans, enabling individuals
to learn new tasks by observing and imitating experts. However, applying this
ability to robots presents significant challenges due to the inherent
differences between human and robot embodiments in both their visual appearance
and physical capabilities. While previous methods bridge this gap using
cross-embodiment datasets with shared scenes and tasks, collecting such aligned
data between humans and robots at scale is not trivial. In this paper, we
propose UniSkill, a novel framework that learns embodiment-agnostic skill
representations from large-scale cross-embodiment video data without any
labels, enabling skills extracted from human video prompts to effectively
transfer to robot policies trained only on robot data. Our experiments in both
simulation and real-world environments show that our cross-embodiment skills
successfully guide robots in selecting appropriate actions, even with unseen
video prompts. The project website can be found at:
https://kimhanjung.github.io/UniSkill.
</summary>
    <author>
      <name>Hanjung Kim</name>
    </author>
    <author>
      <name>Jaehyun Kang</name>
    </author>
    <author>
      <name>Hyolim Kang</name>
    </author>
    <author>
      <name>Meedeum Cho</name>
    </author>
    <author>
      <name>Seon Joo Kim</name>
    </author>
    <author>
      <name>Youngwoon Lee</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Project Page: https://kimhanjung.github.io/UniSkill/</arxiv:comment>
    <link href="http://arxiv.org/abs/2505.08787v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.08787v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.08784v1</id>
    <updated>2025-05-13T17:58:16Z</updated>
    <published>2025-05-13T17:58:16Z</published>
    <title>PCS-UQ: Uncertainty Quantification via the
  Predictability-Computability-Stability Framework</title>
    <summary>  As machine learning (ML) models are increasingly deployed in high-stakes
domains, trustworthy uncertainty quantification (UQ) is critical for ensuring
the safety and reliability of these models. Traditional UQ methods rely on
specifying a true generative model and are not robust to misspecification. On
the other hand, conformal inference allows for arbitrary ML models but does not
consider model selection, which leads to large interval sizes. We tackle these
drawbacks by proposing a UQ method based on the predictability, computability,
and stability (PCS) framework for veridical data science proposed by Yu and
Kumbier. Specifically, PCS-UQ addresses model selection by using a prediction
check to screen out unsuitable models. PCS-UQ then fits these screened
algorithms across multiple bootstraps to assess inter-sample variability and
algorithmic instability, enabling more reliable uncertainty estimates. Further,
we propose a novel calibration scheme that improves local adaptivity of our
prediction sets. Experiments across $17$ regression and $6$ classification
datasets show that PCS-UQ achieves the desired coverage and reduces width over
conformal approaches by $\approx 20\%$. Further, our local analysis shows
PCS-UQ often achieves target coverage across subgroups while conformal methods
fail to do so. For large deep-learning models, we propose computationally
efficient approximation schemes that avoid the expensive multiple bootstrap
trainings of PCS-UQ. Across three computer vision benchmarks, PCS-UQ reduces
prediction set size over conformal methods by $20\%$. Theoretically, we show a
modified PCS-UQ algorithm is a form of split conformal inference and achieves
the desired coverage with exchangeable data.
</summary>
    <author>
      <name>Abhineet Agarwal</name>
    </author>
    <author>
      <name>Michael Xiao</name>
    </author>
    <author>
      <name>Rebecca Barter</name>
    </author>
    <author>
      <name>Omer Ronen</name>
    </author>
    <author>
      <name>Boyu Fan</name>
    </author>
    <author>
      <name>Bin Yu</name>
    </author>
    <link href="http://arxiv.org/abs/2505.08784v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.08784v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ME" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.08783v1</id>
    <updated>2025-05-13T17:58:08Z</updated>
    <published>2025-05-13T17:58:08Z</published>
    <title>CodePDE: An Inference Framework for LLM-driven PDE Solver Generation</title>
    <summary>  Partial differential equations (PDEs) are fundamental to modeling physical
systems, yet solving them remains a complex challenge. Traditional numerical
solvers rely on expert knowledge to implement and are computationally
expensive, while neural-network-based solvers require large training datasets
and often lack interpretability. In this work, we frame PDE solving as a code
generation task and introduce CodePDE, the first inference framework for
generating PDE solvers using large language models (LLMs). Leveraging advanced
inference-time algorithms and scaling strategies, CodePDE unlocks critical
capacities of LLM for PDE solving: reasoning, debugging, selfrefinement, and
test-time scaling -- all without task-specific tuning. CodePDE achieves
superhuman performance across a range of representative PDE problems. We also
present a systematic empirical analysis of LLM generated solvers, analyzing
their accuracy, efficiency, and numerical scheme choices. Our findings
highlight the promise and the current limitations of LLMs in PDE solving,
offering a new perspective on solver design and opportunities for future model
development. Our code is available at https://github.com/LithiumDA/CodePDE.
</summary>
    <author>
      <name>Shanda Li</name>
    </author>
    <author>
      <name>Tanya Marwah</name>
    </author>
    <author>
      <name>Junhong Shen</name>
    </author>
    <author>
      <name>Weiwei Sun</name>
    </author>
    <author>
      <name>Andrej Risteski</name>
    </author>
    <author>
      <name>Yiming Yang</name>
    </author>
    <author>
      <name>Ameet Talwalkar</name>
    </author>
    <link href="http://arxiv.org/abs/2505.08783v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.08783v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.NA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.NA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.08782v1</id>
    <updated>2025-05-13T17:57:53Z</updated>
    <published>2025-05-13T17:57:53Z</published>
    <title>Addressing the Current Challenges of Quantum Machine Learning through
  Multi-Chip Ensembles</title>
    <summary>  Quantum Machine Learning (QML) holds significant promise for solving
computational challenges across diverse domains. However, its practical
deployment is constrained by the limitations of noisy intermediate-scale
quantum (NISQ) devices, including noise, limited scalability, and trainability
issues in variational quantum circuits (VQCs). We introduce the multi-chip
ensemble VQC framework, which partitions high-dimensional computations across
smaller quantum chips to enhance scalability, trainability, and noise
resilience. We show that this approach mitigates barren plateaus, reduces
quantum error bias and variance, and maintains robust generalization through
controlled entanglement. Designed to align with current and emerging quantum
hardware, the framework demonstrates strong potential for enabling scalable QML
on near-term devices, as validated by experiments on standard benchmark
datasets (MNIST, FashionMNIST, CIFAR-10) and real world dataset (PhysioNet
EEG).
</summary>
    <author>
      <name>Junghoon Justin Park</name>
    </author>
    <author>
      <name>Jiook Cha</name>
    </author>
    <author>
      <name>Samuel Yen-Chi Chen</name>
    </author>
    <author>
      <name>Huan-Hsin Tseng</name>
    </author>
    <author>
      <name>Shinjae Yoo</name>
    </author>
    <link href="http://arxiv.org/abs/2505.08782v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.08782v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
