<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Adeep%20learning%26id_list%3D%26start%3D0%26max_results%3D5" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:deep learning&amp;id_list=&amp;start=0&amp;max_results=5</title>
  <id>http://arxiv.org/api/o6m5I8YDMO+W1ZfiBhSOoh9xyHo</id>
  <updated>2025-06-18T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">435412</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">5</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2506.14769v1</id>
    <updated>2025-06-17T17:59:12Z</updated>
    <published>2025-06-17T17:59:12Z</published>
    <title>CDP: Towards Robust Autoregressive Visuomotor Policy Learning via Causal
  Diffusion</title>
    <summary>  Diffusion Policy (DP) enables robots to learn complex behaviors by imitating
expert demonstrations through action diffusion. However, in practical
applications, hardware limitations often degrade data quality, while real-time
constraints restrict model inference to instantaneous state and scene
observations. These limitations seriously reduce the efficacy of learning from
expert demonstrations, resulting in failures in object localization, grasp
planning, and long-horizon task execution. To address these challenges, we
propose Causal Diffusion Policy (CDP), a novel transformer-based diffusion
model that enhances action prediction by conditioning on historical action
sequences, thereby enabling more coherent and context-aware visuomotor policy
learning. To further mitigate the computational cost associated with
autoregressive inference, a caching mechanism is also introduced to store
attention key-value pairs from previous timesteps, substantially reducing
redundant computations during execution. Extensive experiments in both
simulated and real-world environments, spanning diverse 2D and 3D manipulation
tasks, demonstrate that CDP uniquely leverages historical action sequences to
achieve significantly higher accuracy than existing methods. Moreover, even
when faced with degraded input observation quality, CDP maintains remarkable
precision by reasoning through temporal continuity, which highlights its
practical robustness for robotic control under realistic, imperfect conditions.
</summary>
    <author>
      <name>Jiahua Ma</name>
    </author>
    <author>
      <name>Yiran Qin</name>
    </author>
    <author>
      <name>Yixiong Li</name>
    </author>
    <author>
      <name>Xuanqi Liao</name>
    </author>
    <author>
      <name>Yulan Guo</name>
    </author>
    <author>
      <name>Ruimao Zhang</name>
    </author>
    <link href="http://arxiv.org/abs/2506.14769v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.14769v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.14767v1</id>
    <updated>2025-06-17T17:58:17Z</updated>
    <published>2025-06-17T17:58:17Z</published>
    <title>A Variational Framework for Improving Naturalness in Generative Spoken
  Language Models</title>
    <summary>  The success of large language models in text processing has inspired their
adaptation to speech modeling. However, since speech is continuous and complex,
it is often discretized for autoregressive modeling. Speech tokens derived from
self-supervised models (known as semantic tokens) typically focus on the
linguistic aspects of speech but neglect prosodic information. As a result,
models trained on these tokens can generate speech with reduced naturalness.
Existing approaches try to fix this by adding pitch features to the semantic
tokens. However, pitch alone cannot fully represent the range of paralinguistic
attributes, and selecting the right features requires careful hand-engineering.
To overcome this, we propose an end-to-end variational approach that
automatically learns to encode these continuous speech attributes to enhance
the semantic tokens. Our approach eliminates the need for manual extraction and
selection of paralinguistic features. Moreover, it produces preferred speech
continuations according to human raters. Code, samples and models are available
at https://github.com/b04901014/vae-gslm.
</summary>
    <author>
      <name>Li-Wei Chen</name>
    </author>
    <author>
      <name>Takuya Higuchi</name>
    </author>
    <author>
      <name>Zakaria Aldeneh</name>
    </author>
    <author>
      <name>Ahmed Hussen Abdelaziz</name>
    </author>
    <author>
      <name>Alexander Rudnicky</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">International Conference on Machine Learning (ICML) 2025</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.14767v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.14767v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.AS" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.14764v1</id>
    <updated>2025-06-17T17:57:55Z</updated>
    <published>2025-06-17T17:57:55Z</published>
    <title>Gravitational-wave background detection using machine learning</title>
    <summary>  Extracting the faint gravitational-wave background (GWB) signal from dominant
detector noise and disentangling its %diverse astrophysical and cosmological
components remain significant challenges for traditional methods like
cross-correlation analysis. We propose a novel hybrid approach that combines
deep learning with Bayesian inference to identify and characterize the GWB more
rapidly than current techniques. Our method utilizes a custom-designed
multi-scale multi-headed autoencoder (MSMHAutoencoder) architecture to separate
GWB signals from detector noise, and subsequently Marcov Chain Monte Carlo
parameter estimation to disentangle the GWB components. Using simulated data
representative of the LIGO-Virgo-KAGRA network at design sensitivity, we show
that our MSMHAutoencoder can detect with high confidence (log noise Bayes
factor of 3) a GWB from binary black hole mergers with fractional energy
density $\Omega_{\text{BBH}} \approx 10^{-9}$ at 25 Hz. In the presence of such
an astrophysical GWB, we can simultaneously measure a cosmological component as
faint as $\Omega_{\text{Cosmo}} \approx 1.3 \times 10^{-10}$ using 47.4 days of
training data.
</summary>
    <author>
      <name>Hugo Einsle</name>
    </author>
    <author>
      <name>Marie-Anne Bizouard</name>
    </author>
    <author>
      <name>Tania Regimbau</name>
    </author>
    <author>
      <name>Mairi Sakellariadou</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">17 pages, 7 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.14764v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.14764v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
    <category term="gr-qc" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.HE" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.14762v1</id>
    <updated>2025-06-17T17:55:42Z</updated>
    <published>2025-06-17T17:55:42Z</published>
    <title>Markov Regime-Switching Intelligent Driver Model for Interpretable
  Car-Following Behavior</title>
    <summary>  Accurate and interpretable car-following models are essential for traffic
simulation and autonomous vehicle development. However, classical models like
the Intelligent Driver Model (IDM) are fundamentally limited by their
parsimonious and single-regime structure. They fail to capture the multi-modal
nature of human driving, where a single driving state (e.g., speed, relative
speed, and gap) can elicit many different driver actions. This forces the model
to average across distinct behaviors, reducing its fidelity and making its
parameters difficult to interpret. To overcome this, we introduce a
regime-switching framework that allows driving behavior to be governed by
different IDM parameter sets, each corresponding to an interpretable behavioral
mode. This design enables the model to dynamically switch between interpretable
behavioral modes, rather than averaging across diverse driving contexts. We
instantiate the framework using a Factorial Hidden Markov Model with IDM
dynamics (FHMM-IDM), which explicitly separates intrinsic driving regimes
(e.g., aggressive acceleration, steady-state following) from external traffic
scenarios (e.g., free-flow, congestion, stop-and-go) through two independent
latent Markov processes. Bayesian inference via Markov chain Monte Carlo (MCMC)
is used to jointly estimate the regime-specific parameters, transition
dynamics, and latent state trajectories. Experiments on the HighD dataset
demonstrate that FHMM-IDM uncovers interpretable structure in human driving,
effectively disentangling internal driver actions from contextual traffic
conditions and revealing dynamic regime-switching patterns. This framework
provides a tractable and principled solution to modeling context-dependent
driving behavior under uncertainty, offering improvements in the fidelity of
traffic simulations, the efficacy of safety analyses, and the development of
more human-centric ADAS.
</summary>
    <author>
      <name>Chengyuan Zhang</name>
    </author>
    <author>
      <name>Cathy Wu</name>
    </author>
    <author>
      <name>Lijun Sun</name>
    </author>
    <link href="http://arxiv.org/abs/2506.14762v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.14762v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.14761v1</id>
    <updated>2025-06-17T17:55:11Z</updated>
    <published>2025-06-17T17:55:11Z</published>
    <title>From Bytes to Ideas: Language Modeling with Autoregressive U-Nets</title>
    <summary>  Tokenization imposes a fixed granularity on the input text, freezing how a
language model operates on data and how far in the future it predicts. Byte
Pair Encoding (BPE) and similar schemes split text once, build a static
vocabulary, and leave the model stuck with that choice. We relax this rigidity
by introducing an autoregressive U-Net that learns to embed its own tokens as
it trains. The network reads raw bytes, pools them into words, then pairs of
words, then up to 4 words, giving it a multi-scale view of the sequence. At
deeper stages, the model must predict further into the future -- anticipating
the next few words rather than the next byte -- so deeper stages focus on
broader semantic patterns while earlier stages handle fine details. When
carefully tuning and controlling pretraining compute, shallow hierarchies tie
strong BPE baselines, and deeper hierarchies have a promising trend. Because
tokenization now lives inside the model, the same system can handle
character-level tasks and carry knowledge across low-resource languages.
</summary>
    <author>
      <name>Mathurin Videau</name>
    </author>
    <author>
      <name>Badr Youbi Idrissi</name>
    </author>
    <author>
      <name>Alessandro Leite</name>
    </author>
    <author>
      <name>Marc Schoenauer</name>
    </author>
    <author>
      <name>Olivier Teytaud</name>
    </author>
    <author>
      <name>David Lopez-Paz</name>
    </author>
    <link href="http://arxiv.org/abs/2506.14761v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.14761v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
