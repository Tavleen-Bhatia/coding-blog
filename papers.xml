<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Adeep%20learning%26id_list%3D%26start%3D0%26max_results%3D5" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:deep learning&amp;id_list=&amp;start=0&amp;max_results=5</title>
  <id>http://arxiv.org/api/o6m5I8YDMO+W1ZfiBhSOoh9xyHo</id>
  <updated>2025-04-25T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">420845</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">5</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2504.17782v1</id>
    <updated>2025-04-24T17:58:21Z</updated>
    <published>2025-04-24T17:58:21Z</published>
    <title>Unleashing the Power of Natural Audio Featuring Multiple Sound Sources</title>
    <summary>  Universal sound separation aims to extract clean audio tracks corresponding
to distinct events from mixed audio, which is critical for artificial auditory
perception. However, current methods heavily rely on artificially mixed audio
for training, which limits their ability to generalize to naturally mixed audio
collected in real-world environments. To overcome this limitation, we propose
ClearSep, an innovative framework that employs a data engine to decompose
complex naturally mixed audio into multiple independent tracks, thereby
allowing effective sound separation in real-world scenarios. We introduce two
remix-based evaluation metrics to quantitatively assess separation quality and
use these metrics as thresholds to iteratively apply the data engine alongside
model training, progressively optimizing separation performance. In addition,
we propose a series of training strategies tailored to these separated
independent tracks to make the best use of them. Extensive experiments
demonstrate that ClearSep achieves state-of-the-art performance across multiple
sound separation tasks, highlighting its potential for advancing sound
separation in natural audio scenarios. For more examples and detailed results,
please visit our demo page at https://clearsep.github.io.
</summary>
    <author>
      <name>Xize Cheng</name>
    </author>
    <author>
      <name>Slytherin Wang</name>
    </author>
    <author>
      <name>Zehan Wang</name>
    </author>
    <author>
      <name>Rongjie Huang</name>
    </author>
    <author>
      <name>Tao Jin</name>
    </author>
    <author>
      <name>Zhou Zhao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Work in Progress</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.17782v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.17782v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SD" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.17780v1</id>
    <updated>2025-04-24T17:56:22Z</updated>
    <published>2025-04-24T17:56:22Z</published>
    <title>Replay to Remember: Retaining Domain Knowledge in Streaming Language
  Models</title>
    <summary>  Continual learning in large language models (LLMs) typically encounters the
critical challenge of catastrophic forgetting, where previously acquired
knowledge deteriorates upon exposure to new data. While techniques like replay
buffers and parameter-efficient tuning (e.g., Low-Rank Adaptation or LoRA) have
been proposed, few studies investigate real-time domain adaptation under strict
computational and data-stream constraints. In this paper, we demonstrate a
lightweight method combining LoRA and a minimal replay mechanism in a realistic
streaming setting across three diverse knowledge domains: medical question
answering, genetics, and law. Using perplexity, semantic similarity, and
GPT-based human-like evaluation metrics, we quantify the model's adaptation,
forgetting, and recovery over time. Our experiments reveal that while
catastrophic forgetting naturally occurs, even minimal replay significantly
stabilizes and partially restores domain-specific knowledge. This study
contributes practical insights for deploying adaptable LLMs in
resource-constrained, real-world scenarios.
</summary>
    <author>
      <name>Sneh Pillai</name>
      <arxiv:affiliation xmlns:arxiv="http://arxiv.org/schemas/atom">University of Massachusetts Dartmouth</arxiv:affiliation>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">8 pages 3 figures, 3 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.17780v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.17780v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.17771v1</id>
    <updated>2025-04-24T17:46:29Z</updated>
    <published>2025-04-24T17:46:29Z</published>
    <title>Integrating Learning-Based Manipulation and Physics-Based Locomotion for
  Whole-Body Badminton Robot Control</title>
    <summary>  Learning-based methods, such as imitation learning (IL) and reinforcement
learning (RL), can produce excel control policies over challenging agile robot
tasks, such as sports robot. However, no existing work has harmonized
learning-based policy with model-based methods to reduce training complexity
and ensure the safety and stability for agile badminton robot control. In this
paper, we introduce \ourmethod, a novel hybrid control system for agile
badminton robots. Specifically, we propose a model-based strategy for chassis
locomotion which provides a base for arm policy. We introduce a
physics-informed ``IL+RL'' training framework for learning-based arm policy. In
this train framework, a model-based strategy with privileged information is
used to guide arm policy training during both IL and RL phases. In addition, we
train the critic model during IL phase to alleviate the performance drop issue
when transitioning from IL to RL. We present results on our self-engineered
badminton robot, achieving 94.5% success rate against the serving machine and
90.7% success rate against human players. Our system can be easily generalized
to other agile mobile manipulation tasks such as agile catching and table
tennis. Our project website: https://dreamstarring.github.io/HAMLET/.
</summary>
    <author>
      <name>Haochen Wang</name>
    </author>
    <author>
      <name>Zhiwei Shi</name>
    </author>
    <author>
      <name>Chengxi Zhu</name>
    </author>
    <author>
      <name>Yafei Qiao</name>
    </author>
    <author>
      <name>Cheng Zhang</name>
    </author>
    <author>
      <name>Fan Yang</name>
    </author>
    <author>
      <name>Pengjie Ren</name>
    </author>
    <author>
      <name>Lan Lu</name>
    </author>
    <author>
      <name>Dong Xuan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Accepted to ICRA 2025. Project page:
  https://dreamstarring.github.io/HAMLET/</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.17771v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.17771v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.17768v1</id>
    <updated>2025-04-24T17:39:25Z</updated>
    <published>2025-04-24T17:39:25Z</published>
    <title>The Sparse Frontier: Sparse Attention Trade-offs in Transformer LLMs</title>
    <summary>  Sparse attention offers a promising strategy to extend long-context
capabilities in Transformer LLMs, yet its viability, its efficiency-accuracy
trade-offs, and systematic scaling studies remain unexplored. To address this
gap, we perform a careful comparison of training-free sparse attention methods
at varying model scales, sequence lengths, and sparsity levels on a diverse
collection of long-sequence tasks-including novel ones that rely on natural
language while remaining controllable and easy to evaluate. Based on our
experiments, we report a series of key findings: 1) an isoFLOPS analysis
reveals that for very long sequences, larger and highly sparse models are
preferable to smaller and dense ones. 2) The level of sparsity attainable while
statistically guaranteeing accuracy preservation is higher during decoding than
prefilling, and correlates with model size in the former. 3) There is no clear
strategy that performs best across tasks and phases, with different units of
sparsification or budget adaptivity needed for different scenarios. Even
moderate sparsity levels often result in significant performance degradation on
at least one task, highlighting that sparse attention is not a universal
solution. 4) We introduce and validate novel scaling laws specifically tailored
for sparse attention, providing evidence that our findings are likely to hold
true beyond our range of experiments. Through these insights, we demonstrate
that sparse attention is a key tool to enhance the capabilities of Transformer
LLMs for processing longer sequences, but requires careful evaluation of
trade-offs for performance-sensitive applications.
</summary>
    <author>
      <name>Piotr Nawrot</name>
    </author>
    <author>
      <name>Robert Li</name>
    </author>
    <author>
      <name>Renjie Huang</name>
    </author>
    <author>
      <name>Sebastian Ruder</name>
    </author>
    <author>
      <name>Kelly Marchisio</name>
    </author>
    <author>
      <name>Edoardo M. Ponti</name>
    </author>
    <link href="http://arxiv.org/abs/2504.17768v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.17768v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.17752v1</id>
    <updated>2025-04-24T17:10:18Z</updated>
    <published>2025-04-24T17:10:18Z</published>
    <title>Disaggregated Deep Learning via In-Physics Computing at Radio Frequency</title>
    <summary>  Modern edge devices, such as cameras, drones, and Internet-of-Things nodes,
rely on deep learning to enable a wide range of intelligent applications,
including object recognition, environment perception, and autonomous
navigation. However, deploying deep learning models directly on the often
resource-constrained edge devices demands significant memory footprints and
computational power for real-time inference using traditional digital computing
architectures. In this paper, we present WISE, a novel computing architecture
for wireless edge networks designed to overcome energy constraints in deep
learning inference. WISE achieves this goal through two key innovations:
disaggregated model access via wireless broadcasting and in-physics computation
of general complex-valued matrix-vector multiplications directly at radio
frequency. Using a software-defined radio platform with wirelessly broadcast
model weights over the air, we demonstrate that WISE achieves 95.7% image
classification accuracy with ultra-low operation power of 6.0 fJ/MAC per
client, corresponding to a computation efficiency of 165.8 TOPS/W. This
approach enables energy-efficient deep learning inference on wirelessly
connected edge devices, achieving more than two orders of magnitude improvement
in efficiency compared to traditional digital computing.
</summary>
    <author>
      <name>Zhihui Gao</name>
    </author>
    <author>
      <name>Sri Krishna Vadlamani</name>
    </author>
    <author>
      <name>Kfir Sulimany</name>
    </author>
    <author>
      <name>Dirk Englund</name>
    </author>
    <author>
      <name>Tingjun Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 4 figures. Supplementary Information: 54 pages, 20 figures,
  1 table</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.17752v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.17752v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.ET" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SP" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.app-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
