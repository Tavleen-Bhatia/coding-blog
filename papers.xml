<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Adeep%20learning%26id_list%3D%26start%3D0%26max_results%3D5" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:deep learning&amp;id_list=&amp;start=0&amp;max_results=5</title>
  <id>http://arxiv.org/api/o6m5I8YDMO+W1ZfiBhSOoh9xyHo</id>
  <updated>2025-03-24T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">413872</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">5</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2503.17362v1</id>
    <updated>2025-03-21T17:59:48Z</updated>
    <published>2025-03-21T17:59:48Z</published>
    <title>Criteria for unbiased estimation: applications to noise-agnostic sensing
  and learnability of quantum channel</title>
    <summary>  We establish the necessary and sufficient conditions for unbiased estimation
in multi-parameter estimation tasks. More specifically, we first consider
quantum state estimation, where multiple parameters are encoded in a quantum
state, and derive two equivalent necessary and sufficient conditions for an
unbiased estimation: one formulated in terms of the quantum Fisher information
matrix (QFIM) and the other based on the derivatives of the encoded state.
Furthermore, we introduce a generalized quantum Cram\'er-Rao bound, which
provides a fundamental achievable lower bound on the estimation error even when
the QFIM is non-invertible. To demonstrate the utility of our framework, we
consider phase estimation under unknown Pauli noise. We show that while
unbiased phase estimation is infeasible with a naive scheme, employing an
entangled probe with a noiseless ancilla enables unbiased estimation. Next, we
extend our analysis to quantum channel estimation (equivalently, quantum
channel learning), where the goal is to estimate parameters characterizing an
unknown quantum channel. We establish the necessary and sufficient condition
for unbiased estimation of these parameters. Notably, by interpreting unbiased
estimation as learnability, our result applies to the fundamental learnability
of parameters in general quantum channels. As a concrete application, we
investigate the learnability of noise affecting non-Clifford gates via cycle
benchmarking.
</summary>
    <author>
      <name>Hyukgun Kwon</name>
    </author>
    <author>
      <name>Kento Tsubouchi</name>
    </author>
    <author>
      <name>Chia-Tung Chu</name>
    </author>
    <author>
      <name>Liang Jiang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">2 figures, 5 pages of main text, 18 pages of supplemental matrerial</arxiv:comment>
    <link href="http://arxiv.org/abs/2503.17362v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.17362v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.17361v1</id>
    <updated>2025-03-21T17:59:43Z</updated>
    <published>2025-03-21T17:59:43Z</published>
    <title>Gumbel-Softmax Flow Matching with Straight-Through Guidance for
  Controllable Biological Sequence Generation</title>
    <summary>  Flow matching in the continuous simplex has emerged as a promising strategy
for DNA sequence design, but struggles to scale to higher simplex dimensions
required for peptide and protein generation. We introduce Gumbel-Softmax Flow
and Score Matching, a generative framework on the simplex based on a novel
Gumbel-Softmax interpolant with a time-dependent temperature. Using this
interpolant, we introduce Gumbel-Softmax Flow Matching by deriving a
parameterized velocity field that transports from smooth categorical
distributions to distributions concentrated at a single vertex of the simplex.
We alternatively present Gumbel-Softmax Score Matching which learns to regress
the gradient of the probability density. Our framework enables high-quality,
diverse generation and scales efficiently to higher-dimensional simplices. To
enable training-free guidance, we propose Straight-Through Guided Flows
(STGFlow), a classifier-based guidance method that leverages straight-through
estimators to steer the unconditional velocity field toward optimal vertices of
the simplex. STGFlow enables efficient inference-time guidance using
classifiers pre-trained on clean sequences, and can be used with any discrete
flow method. Together, these components form a robust framework for
controllable de novo sequence generation. We demonstrate state-of-the-art
performance in conditional DNA promoter design, sequence-only protein
generation, and target-binding peptide design for rare disease treatment.
</summary>
    <author>
      <name>Sophia Tang</name>
    </author>
    <author>
      <name>Yinuo Zhang</name>
    </author>
    <author>
      <name>Alexander Tong</name>
    </author>
    <author>
      <name>Pranam Chatterjee</name>
    </author>
    <link href="http://arxiv.org/abs/2503.17361v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.17361v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.BM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.17355v2</id>
    <updated>2025-03-24T13:10:28Z</updated>
    <published>2025-03-21T17:58:10Z</published>
    <title>Glivenko-Cantelli for $f$-divergence</title>
    <summary>  We extend the celebrated Glivenko-Cantelli theorem, sometimes called the
fundamental theorem of statistics, from its standard setting of total variation
distance to all $f$-divergences. A key obstacle in this endeavor is to define
$f$-divergence on a subcollection of a $\sigma$-algebra that forms a
$\pi$-system but not a $\sigma$-subalgebra. This is a side contribution of our
work. We will show that this notion of $f$-divergence on the $\pi$-system of
rays preserves nearly all known properties of standard $f$-divergence, yields a
novel integral representation of the Kolmogorov-Smirnov distance, and has a
Glivenko-Cantelli theorem. We will also discuss the prospects of a
Vapnik-Chervonenkis theory for $f$-divergence.
</summary>
    <author>
      <name>Haoming Wang</name>
    </author>
    <author>
      <name>Lek-Heng Lim</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">26 pages, 1 figure</arxiv:comment>
    <link href="http://arxiv.org/abs/2503.17355v2" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.17355v2" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
    <category term="60B10, 60F15, 60F25" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.17354v1</id>
    <updated>2025-03-21T17:54:01Z</updated>
    <published>2025-03-21T17:54:01Z</published>
    <title>HCAST: Human-Calibrated Autonomy Software Tasks</title>
    <summary>  To understand and predict the societal impacts of highly autonomous AI
systems, we need benchmarks with grounding, i.e., metrics that directly connect
AI performance to real-world effects we care about. We present HCAST
(Human-Calibrated Autonomy Software Tasks), a benchmark of 189 machine learning
engineering, cybersecurity, software engineering, and general reasoning tasks.
We collect 563 human baselines (totaling over 1500 hours) from people skilled
in these domains, working under identical conditions as AI agents, which lets
us estimate that HCAST tasks take humans between one minute and 8+ hours.
Measuring the time tasks take for humans provides an intuitive metric for
evaluating AI capabilities, helping answer the question "can an agent be
trusted to complete a task that would take a human X hours?" We evaluate the
success rates of AI agents built on frontier foundation models, and we find
that current agents succeed 70-80% of the time on tasks that take humans less
than one hour, and less than 20% of the time on tasks that take humans more
than 4 hours.
</summary>
    <author>
      <name>David Rein</name>
    </author>
    <author>
      <name>Joel Becker</name>
    </author>
    <author>
      <name>Amy Deng</name>
    </author>
    <author>
      <name>Seraphina Nix</name>
    </author>
    <author>
      <name>Chris Canal</name>
    </author>
    <author>
      <name>Daniel O'Connel</name>
    </author>
    <author>
      <name>Pip Arnott</name>
    </author>
    <author>
      <name>Ryan Bloom</name>
    </author>
    <author>
      <name>Thomas Broadley</name>
    </author>
    <author>
      <name>Katharyn Garcia</name>
    </author>
    <author>
      <name>Brian Goodrich</name>
    </author>
    <author>
      <name>Max Hasin</name>
    </author>
    <author>
      <name>Sami Jawhar</name>
    </author>
    <author>
      <name>Megan Kinniment</name>
    </author>
    <author>
      <name>Thomas Kwa</name>
    </author>
    <author>
      <name>Aron Lajko</name>
    </author>
    <author>
      <name>Nate Rush</name>
    </author>
    <author>
      <name>Lucas Jun Koba Sato</name>
    </author>
    <author>
      <name>Sydney Von Arx</name>
    </author>
    <author>
      <name>Ben West</name>
    </author>
    <author>
      <name>Lawrence Chan</name>
    </author>
    <author>
      <name>Elizabeth Barnes</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">32 pages, 10 figures, 5 tables</arxiv:comment>
    <link href="http://arxiv.org/abs/2503.17354v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.17354v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="I.2.0" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2503.17353v1</id>
    <updated>2025-03-21T17:52:44Z</updated>
    <published>2025-03-21T17:52:44Z</published>
    <title>NdLinear Is All You Need for Representation Learning</title>
    <summary>  Many high-impact machine learning tasks involve multi-dimensional data (e.g.,
images, volumetric medical scans, multivariate time-series). Yet, most neural
architectures flatten inputs, discarding critical cross-dimension information.
We introduce NdLinear, a novel linear transformation that preserves these
structures without extra overhead. By operating separately along each
dimension, NdLinear captures dependencies that standard fully connected layers
overlook. Extensive experiments across convolutional, recurrent, and
transformer-based networks show significant improvements in representational
power and parameter efficiency. Crucially, NdLinear serves as a foundational
building block for large-scale foundation models by operating on any unimodal
or multimodal data in its native form. This removes the need for flattening or
modality-specific preprocessing. Ndlinear rethinks core architectural
priorities beyond attention, enabling more expressive, context-aware models at
scale. We propose NdLinear as a drop-in replacement for standard linear layers
-- marking an important step toward next-generation neural architectures.
</summary>
    <author>
      <name>Alex Reneau</name>
    </author>
    <author>
      <name>Jerry Yao-Chieh Hu</name>
    </author>
    <author>
      <name>Zhongfang Zhuang</name>
    </author>
    <author>
      <name>Ting-Chun Liu</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Code is available at https://github.com/ensemble-core/NdLinear</arxiv:comment>
    <link href="http://arxiv.org/abs/2503.17353v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2503.17353v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
