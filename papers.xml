<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Adeep%20learning%26id_list%3D%26start%3D0%26max_results%3D5" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:deep learning&amp;id_list=&amp;start=0&amp;max_results=5</title>
  <id>http://arxiv.org/api/o6m5I8YDMO+W1ZfiBhSOoh9xyHo</id>
  <updated>2025-04-28T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">421053</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">5</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2504.18538v1</id>
    <updated>2025-04-25T17:59:59Z</updated>
    <published>2025-04-25T17:59:59Z</published>
    <title>Generalization Capability for Imitation Learning</title>
    <summary>  Imitation learning holds the promise of equipping robots with versatile
skills by learning from expert demonstrations. However, policies trained on
finite datasets often struggle to generalize beyond the training distribution.
In this work, we present a unified perspective on the generalization capability
of imitation learning, grounded in both information theorey and data
distribution property. We first show that the generalization gap can be upper
bounded by (i) the conditional information bottleneck on intermediate
representations and (ii) the mutual information between the model parameters
and the training dataset. This characterization provides theoretical guidance
for designing effective training strategies in imitation learning, particularly
in determining whether to freeze, fine-tune, or train large pretrained encoders
(e.g., vision-language models or vision foundation models) from scratch to
achieve better generalization. Furthermore, we demonstrate that high
conditional entropy from input to output induces a flatter likelihood
landscape, thereby reducing the upper bound on the generalization gap. In
addition, it shortens the stochastic gradient descent (SGD) escape time from
sharp local minima, which may increase the likelihood of reaching global optima
under fixed optimization budgets. These insights explain why imitation learning
often exhibits limited generalization and underscore the importance of not only
scaling the diversity of input data but also enriching the variability of
output labels conditioned on the same input.
</summary>
    <author>
      <name>Yixiao Wang</name>
    </author>
    <link href="http://arxiv.org/abs/2504.18538v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.18538v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.18536v1</id>
    <updated>2025-04-25T17:59:14Z</updated>
    <published>2025-04-25T17:59:14Z</published>
    <title>Adapting Probabilistic Risk Assessment for AI</title>
    <summary>  Modern general-purpose artificial intelligence (AI) systems present an urgent
risk management challenge, as their rapidly evolving capabilities and potential
for catastrophic harm outpace our ability to reliably assess their risks.
Current methods often rely on selective testing and undocumented assumptions
about risk priorities, frequently failing to make a serious attempt at
assessing the set of pathways through which Al systems pose direct or indirect
risks to society and the biosphere. This paper introduces the probabilistic
risk assessment (PRA) for AI framework, adapting established PRA techniques
from high-reliability industries (e.g., nuclear power, aerospace) for the new
challenges of advanced AI. The framework guides assessors in identifying
potential risks, estimating likelihood and severity, and explicitly documenting
evidence, underlying assumptions, and analyses at appropriate granularities.
The framework's implementation tool synthesizes the results into a risk report
card with aggregated risk estimates from all assessed risks. This systematic
approach integrates three advances: (1) Aspect-oriented hazard analysis
provides systematic hazard coverage guided by a first-principles taxonomy of AI
system aspects (e.g. capabilities, domain knowledge, affordances); (2) Risk
pathway modeling analyzes causal chains from system aspects to societal impacts
using bidirectional analysis and incorporating prospective techniques; and (3)
Uncertainty management employs scenario decomposition, reference scales, and
explicit tracing protocols to structure credible projections with novelty or
limited data. Additionally, the framework harmonizes diverse assessment methods
by integrating evidence into comparable, quantified absolute risk estimates for
critical decisions. We have implemented this as a workbook tool for AI
developers, evaluators, and regulators, available on the project website.
</summary>
    <author>
      <name>Anna Katariina Wisakanto</name>
    </author>
    <author>
      <name>Joe Rogero</name>
    </author>
    <author>
      <name>Avyay M. Casheekar</name>
    </author>
    <author>
      <name>Richard Mallah</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">for project website, see https://pra-for-ai.github.io/pra/</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.18536v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.18536v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.AP" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.18535v1</id>
    <updated>2025-04-25T17:59:13Z</updated>
    <published>2025-04-25T17:59:13Z</published>
    <title>TRACE Back from the Future: A Probabilistic Reasoning Approach to
  Controllable Language Generation</title>
    <summary>  As large language models (LMs) advance, there is an increasing need to
control their outputs to align with human values (e.g., detoxification) or
desired attributes (e.g., personalization, topic). However, autoregressive
models focus on next-token predictions and struggle with global properties that
require looking ahead. Existing solutions either tune or post-train LMs for
each new attribute - expensive and inflexible - or approximate the Expected
Attribute Probability (EAP) of future sequences by sampling or training, which
is slow and unreliable for rare attributes. We introduce TRACE (Tractable
Probabilistic Reasoning for Adaptable Controllable gEneration), a novel
framework that efficiently computes EAP and adapts to new attributes through
tractable probabilistic reasoning and lightweight control. TRACE distills a
Hidden Markov Model (HMM) from an LM and pairs it with a small classifier to
estimate attribute probabilities, enabling exact EAP computation over the HMM's
predicted futures. This EAP is then used to reweigh the LM's next-token
probabilities for globally compliant continuations. Empirically, TRACE achieves
state-of-the-art results in detoxification with only 10% decoding overhead,
adapts to 76 low-resource personalized LLMs within seconds, and seamlessly
extends to composite attributes.
</summary>
    <author>
      <name>Gwen Yidou Weng</name>
    </author>
    <author>
      <name>Benjie Wang</name>
    </author>
    <author>
      <name>Guy Van den Broeck</name>
    </author>
    <link href="http://arxiv.org/abs/2504.18535v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.18535v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.18534v1</id>
    <updated>2025-04-25T17:59:10Z</updated>
    <published>2025-04-25T17:59:10Z</published>
    <title>First upper limits on the 21-cm signal power spectrum of neutral
  hydrogen at $z=9.16$ from the LOFAR 3C196 field</title>
    <summary>  The redshifted 21-cm signal of neutral hydrogen from the Epoch of
Reionization (EoR) can potentially be detected using low-frequency radio
instruments such as the Low-Frequency Array (LOFAR). So far, LOFAR upper limits
on the 21-cm signal power spectrum have been published using a single target
field: the North Celestial Pole (NCP). In this work, we analyse and provide
upper limits for the 3C196 field, observed by LOFAR, with a strong
${\approx}80\,$Jy source in the centre. This field offers advantages such as
higher sensitivity due to zenith-crossing observations and reduced
geostationary radio-frequency interference, but also poses challenges due to
the presence of the bright central source. After constructing a wide-field sky
model, we process a single 6-hour night of 3C196 observations using
direction-independent and direction-dependent calibration, followed by a
residual foreground subtraction with a machine learned Gaussian process
regression (ML-GPR). A bias correction is necessary to account for signal
suppression in the GPR step. Still, even after this correction, the upper
limits are a factor of two lower than previous single-night NCP results, with a
lowest $2\sigma$ upper limit of $(146.61\,\text{mK})^2$ at $z = 9.16$ and
$k=0.078\,h\,\text{cMpc}^{-1}$ (with $\text{d}k/k\approx 0.3$). The results
also reveal an excess power, different in behaviour from that observed in the
NCP field, suggesting a potential residual foreground origin. In future work,
the use of multiple nights of 3C196 observations combined with improvements to
sky modelling and ML-GPR to avoid the need for bias correction should provide
tighter constraints per unit observing time than the NCP.
</summary>
    <author>
      <name>E. Ceccotti</name>
    </author>
    <author>
      <name>A. R. Offringa</name>
    </author>
    <author>
      <name>F. G. Mertens</name>
    </author>
    <author>
      <name>L. V. E. Koopmans</name>
    </author>
    <author>
      <name>S. Munshi</name>
    </author>
    <author>
      <name>J. K. Chege</name>
    </author>
    <author>
      <name>A. Acharya</name>
    </author>
    <author>
      <name>S. A. Brackenhoff</name>
    </author>
    <author>
      <name>E. Chapman</name>
    </author>
    <author>
      <name>B. Ciardi</name>
    </author>
    <author>
      <name>R. Ghara</name>
    </author>
    <author>
      <name>S. Ghosh</name>
    </author>
    <author>
      <name>S. K. Giri</name>
    </author>
    <author>
      <name>C. Höfer</name>
    </author>
    <author>
      <name>I. Hothi</name>
    </author>
    <author>
      <name>G. Mellema</name>
    </author>
    <author>
      <name>M. Mevius</name>
    </author>
    <author>
      <name>V. N. Pandey</name>
    </author>
    <author>
      <name>S. Zaroubi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">27 pages, 23 figures, 5 tables. Submitted to MNRAS</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.18534v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.18534v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.CO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.IM" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.18530v1</id>
    <updated>2025-04-25T17:54:27Z</updated>
    <published>2025-04-25T17:54:27Z</published>
    <title>Scaling Laws For Scalable Oversight</title>
    <summary>  Scalable oversight, the process by which weaker AI systems supervise stronger
ones, has been proposed as a key strategy to control future superintelligent
systems. However, it is still unclear how scalable oversight itself scales. To
address this gap, we propose a framework that quantifies the probability of
successful oversight as a function of the capabilities of the overseer and the
system being overseen. Specifically, our framework models oversight as a game
between capability-mismatched players; the players have oversight-specific and
deception-specific Elo scores that are a piecewise-linear function of their
general intelligence, with two plateaus corresponding to task incompetence and
task saturation. We validate our framework with a modified version of the game
Nim and then apply it to four oversight games: "Mafia", "Debate", "Backdoor
Code" and "Wargames". For each game, we find scaling laws that approximate how
domain performance depends on general AI system capability (using Chatbot Arena
Elo as a proxy for general capability). We then build on our findings in a
theoretical study of Nested Scalable Oversight (NSO), a process in which
trusted models oversee untrusted stronger models, which then become the trusted
models in the next step. We identify conditions under which NSO succeeds and
derive numerically (and in some cases analytically) the optimal number of
oversight levels to maximize the probability of oversight success. In our
numerical examples, the NSO success rate is below 52% when overseeing systems
that are 400 Elo points stronger than the baseline overseer, and it declines
further for overseeing even stronger systems.
</summary>
    <author>
      <name>Joshua Engels</name>
    </author>
    <author>
      <name>David D. Baek</name>
    </author>
    <author>
      <name>Subhash Kantamneni</name>
    </author>
    <author>
      <name>Max Tegmark</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">34 pages, 17 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.18530v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.18530v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
