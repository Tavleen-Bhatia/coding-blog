<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Adeep%20learning%26id_list%3D%26start%3D0%26max_results%3D5" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:deep learning&amp;id_list=&amp;start=0&amp;max_results=5</title>
  <id>http://arxiv.org/api/o6m5I8YDMO+W1ZfiBhSOoh9xyHo</id>
  <updated>2025-06-16T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">434520</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">5</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2506.12015v1</id>
    <updated>2025-06-13T17:59:58Z</updated>
    <published>2025-06-13T17:59:58Z</published>
    <title>EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction</title>
    <summary>  Open-source foundation models have seen rapid adoption and development,
enabling powerful general-purpose capabilities across diverse domains. However,
fine-tuning large foundation models for domain-specific or personalized tasks
remains prohibitively expensive for most users due to the significant memory
overhead beyond that of inference. We introduce EMLoC, an Emulator-based
Memory-efficient fine-tuning framework with LoRA Correction, which enables
model fine-tuning within the same memory budget required for inference. EMLoC
constructs a task-specific light-weight emulator using activation-aware
singular value decomposition (SVD) on a small downstream calibration set.
Fine-tuning then is performed on this lightweight emulator via LoRA. To tackle
the misalignment between the original model and the compressed emulator, we
propose a novel compensation algorithm to correct the fine-tuned LoRA module,
which thus can be merged into the original model for inference. EMLoC supports
flexible compression ratios and standard training pipelines, making it
adaptable to a wide range of applications. Extensive experiments demonstrate
that EMLoC outperforms other baselines across multiple datasets and modalities.
Moreover, without quantization, EMLoC enables fine-tuning of a 38B model on a
single 24GB consumer GPU-bringing efficient and practical model adaptation to
individual users.
</summary>
    <author>
      <name>Hsi-Che Lin</name>
    </author>
    <author>
      <name>Yu-Chu Yu</name>
    </author>
    <author>
      <name>Kai-Po Chang</name>
    </author>
    <author>
      <name>Yu-Chiang Frank Wang</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Under review. Project page: https://hsi-che-lin.github.io/EMLoC/</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.12015v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.12015v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.12014v1</id>
    <updated>2025-06-13T17:59:39Z</updated>
    <published>2025-06-13T17:59:39Z</published>
    <title>code_transformed: The Influence of Large Language Models on Code</title>
    <summary>  Coding remains one of the most fundamental modes of interaction between
humans and machines. With the rapid advancement of Large Language Models
(LLMs), code generation capabilities have begun to significantly reshape
programming practices. This development prompts a central question: Have LLMs
transformed code style, and how can such transformation be characterized? In
this paper, we present a pioneering study that investigates the impact of LLMs
on code style, with a focus on naming conventions, complexity, maintainability,
and similarity. By analyzing code from over 19,000 GitHub repositories linked
to arXiv papers published between 2020 and 2025, we identify measurable trends
in the evolution of coding style that align with characteristics of
LLM-generated code. For instance, the proportion of snake\_case variable names
in Python code increased from 47% in Q1 2023 to 51% in Q1 2025. Furthermore, we
investigate how LLMs approach algorithmic problems by examining their reasoning
processes. Given the diversity of LLMs and usage scenarios, among other
factors, it is difficult or even impossible to precisely estimate the
proportion of code generated or assisted by LLMs. Our experimental results
provide the first large-scale empirical evidence that LLMs affect real-world
programming style.
</summary>
    <author>
      <name>Yuliang Xu</name>
    </author>
    <author>
      <name>Siming Huang</name>
    </author>
    <author>
      <name>Mingmeng Geng</name>
    </author>
    <author>
      <name>Yao Wan</name>
    </author>
    <author>
      <name>Xuanhua Shi</name>
    </author>
    <author>
      <name>Dongping Chen</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">We release all the experimental dataset and source code at:
  https://github.com/ignorancex/LLM_code</arxiv:comment>
    <link href="http://arxiv.org/abs/2506.12014v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.12014v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.12010v1</id>
    <updated>2025-06-13T17:58:14Z</updated>
    <published>2025-06-13T17:58:14Z</published>
    <title>A Random Matrix Theory of Pauli Tomography</title>
    <summary>  Quantum state tomography (QST), the process of reconstructing some unknown
quantum state $\hat\rho$ from repeated measurements on copies of said state, is
a foundationally important task in the context of quantum computation and
simulation. For this reason, a detailed characterization of the error
$\Delta\hat\rho = \hat\rho-\hat\rho^\prime$ in a QST reconstruction
$\hat\rho^\prime$ is of clear importance to quantum theory and experiment. In
this work, we develop a fully random matrix theory (RMT) treatment of state
tomography in informationally-complete bases; and in doing so we reveal deep
connections between QST errors $\Delta\hat\rho$ and the gaussian unitary
ensemble (GUE). By exploiting this connection we prove that wide classes of
functions of the spectrum of $\Delta\hat\rho$ can be evaluated by substituting
samples of an appropriate GUE for realizations of $\Delta\hat\rho$. This
powerful and flexible result enables simple analytic treatments of the mean
value and variance of the error as quantified by the trace distance
$\|\Delta\hat\rho\|_\mathrm{Tr}$ (which we validate numerically for common
tomographic protocols), allows us to derive a bound on the QST sample
complexity, and subsequently demonstrate that said bound doesn't change under
the most widely-used rephysicalization procedure. These results collectively
demonstrate the flexibility, strength, and broad applicability of our approach;
and lays the foundation for broader studies of RMT treatments of QST in the
future.
</summary>
    <author>
      <name>Nathan Keenan</name>
    </author>
    <author>
      <name>John Goold</name>
    </author>
    <author>
      <name>Alex Nico-Katz</name>
    </author>
    <link href="http://arxiv.org/abs/2506.12010v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.12010v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="quant-ph" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.ST" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.TH" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.12009v1</id>
    <updated>2025-06-13T17:57:18Z</updated>
    <published>2025-06-13T17:57:18Z</published>
    <title>Affogato: Learning Open-Vocabulary Affordance Grounding with Automated
  Data Generation at Scale</title>
    <summary>  Affordance grounding-localizing object regions based on natural language
descriptions of interactions-is a critical challenge for enabling intelligent
agents to understand and interact with their environments. However, this task
remains challenging due to the need for fine-grained part-level localization,
the ambiguity arising from multiple valid interaction regions, and the scarcity
of large-scale datasets. In this work, we introduce Affogato, a large-scale
benchmark comprising 150K instances, annotated with open-vocabulary text
descriptions and corresponding 3D affordance heatmaps across a diverse set of
objects and interactions. Building on this benchmark, we develop simple yet
effective vision-language models that leverage pretrained part-aware vision
backbones and a text-conditional heatmap decoder. Our models trained with the
Affogato dataset achieve promising performance on the existing 2D and 3D
benchmarks, and notably, exhibit effectiveness in open-vocabulary cross-domain
generalization. The Affogato dataset is shared in public:
https://huggingface.co/datasets/project-affogato/affogato
</summary>
    <author>
      <name>Junha Lee</name>
    </author>
    <author>
      <name>Eunha Park</name>
    </author>
    <author>
      <name>Chunghyun Park</name>
    </author>
    <author>
      <name>Dahyun Kang</name>
    </author>
    <author>
      <name>Minsu Cho</name>
    </author>
    <link href="http://arxiv.org/abs/2506.12009v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.12009v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2506.12007v1</id>
    <updated>2025-06-13T17:56:49Z</updated>
    <published>2025-06-13T17:56:49Z</published>
    <title>SIMSHIFT: A Benchmark for Adapting Neural Surrogates to Distribution
  Shifts</title>
    <summary>  Neural surrogates for Partial Differential Equations (PDEs) often suffer
significant performance degradation when evaluated on unseen problem
configurations, such as novel material types or structural dimensions.
Meanwhile, Domain Adaptation (DA) techniques have been widely used in vision
and language processing to generalize from limited information about unseen
configurations. In this work, we address this gap through two focused
contributions. First, we introduce SIMSHIFT, a novel benchmark dataset and
evaluation suite composed of four industrial simulation tasks: hot rolling,
sheet metal forming, electric motor design and heatsink design. Second, we
extend established domain adaptation methods to state of the art neural
surrogates and systematically evaluate them. These approaches use parametric
descriptions and ground truth simulations from multiple source configurations,
together with only parametric descriptions from target configurations. The goal
is to accurately predict target simulations without access to ground truth
simulation data. Extensive experiments on SIMSHIFT highlight the challenges of
out of distribution neural surrogate modeling, demonstrate the potential of DA
in simulation, and reveal open problems in achieving robust neural surrogates
under distribution shifts in industrially relevant scenarios. Our codebase is
available at https://github.com/psetinek/simshift
</summary>
    <author>
      <name>Paul Setinek</name>
    </author>
    <author>
      <name>Gianluca Galletti</name>
    </author>
    <author>
      <name>Thomas Gross</name>
    </author>
    <author>
      <name>Dominik Schn√ºrer</name>
    </author>
    <author>
      <name>Johannes Brandstetter</name>
    </author>
    <author>
      <name>Werner Zellinger</name>
    </author>
    <link href="http://arxiv.org/abs/2506.12007v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2506.12007v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
