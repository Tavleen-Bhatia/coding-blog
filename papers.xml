<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Adeep%20learning%26id_list%3D%26start%3D0%26max_results%3D5" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:deep learning&amp;id_list=&amp;start=0&amp;max_results=5</title>
  <id>http://arxiv.org/api/o6m5I8YDMO+W1ZfiBhSOoh9xyHo</id>
  <updated>2025-02-26T00:00:00-05:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">407655</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">5</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2502.18464v1</id>
    <updated>2025-02-25T18:59:58Z</updated>
    <published>2025-02-25T18:59:58Z</published>
    <title>Unveiling the Aromatic and Aliphatic Universe at Redshifts
  $z\sim$0.2--0.5 with JWST/NIRCam</title>
    <summary>  Utilizing deep NIRCam/WFSS data from JWST's FRESCO program, we
spectroscopically survey the 3.3 $\mu m$ aromatic and 3.4 $\mu m$ aliphatic
C--H stretching emission bands of polycyclic aromatic hydrocarbon (PAH)
molecules in galaxies at redshifts $z$$\sim$0.2--0.5. Unlike pre-JWST studies,
largely limited to infrared (IR)-bright galaxies ($L_{\rm
IR}\gtrsim10^{11}~L_\odot$) at $z\lesssim0.1$, we probe 200 galaxies down to
$L_{\rm IR}$$\sim$$10^{8.5}$--$10^{10}~L_\odot$ well beyond the local Universe.
The 3.3 $\mu m$ emission is detected at $\geq$3-$\sigma$ in 88 out of 187
galaxies, correlating tightly with galaxy IR luminosity and star formation rate
(SFR) and confirming the 3.3 $\mu m$ PAH as a viable SFR tracer. Despite a
large scatter, the 3.3 $\mu m$-to-IR luminosity ratio ($L_{3.3}/L_{\rm IR}$)
exhibits a strong metallicity dependence with a drop of $L_{3.3}/L_{\rm IR}$ by
a factor of $\gtrsim10$ at 12+log(O/H)$\sim$8.4--8.5 towards lower
metallicities. The 3.4 $\mu m$ emission is detected in 37 out of 159 galaxies,
with the 3.4 $\mu m$-to-3.3 $\mu m$ luminosity ratio ($L_{3.4}/L_{3.3}$)
spanning from $\sim$0.05 to $\sim$0.58 (median $\sim$0.19), corresponding to
PAH aliphatic fractions of $\sim$0.78%--8.3% (median $\sim$2.9%) in terms of
fractional carbon atoms in aliphatic units. While $L_{3.4}/L_{3.3}$ does not
depend significantly on redshift, stellar mass, metallicity, or galaxy
morphology, it does decrease with various SFR tracers, suggesting that
ultraviolet photons in active star-forming regions may strip aliphatic
sidegroups from PAH molecules. Our study showcases the unique power of JWST's
NIRCam/WFSS to systematically map PAH aromatic and aliphatic content in
statistically significant, less-biased galaxy samples, providing critical
insights into PAH chemistry and its connection to galaxy properties.
</summary>
    <author>
      <name>Jianwei Lyu</name>
    </author>
    <author>
      <name>Xuejuan Yang</name>
    </author>
    <author>
      <name>Aigen Li</name>
    </author>
    <author>
      <name>Fengwu Sun</name>
    </author>
    <author>
      <name>George H. Rieke</name>
    </author>
    <author>
      <name>Stacey Alberts</name>
    </author>
    <author>
      <name>Irene Shivaei</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages, 8 figures, 2 tables; submitted to ApJ</arxiv:comment>
    <link href="http://arxiv.org/abs/2502.18464v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.18464v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
    <category term="astro-ph.GA" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.18463v1</id>
    <updated>2025-02-25T18:59:46Z</updated>
    <published>2025-02-25T18:59:46Z</published>
    <title>Allocating Variance to Maximize Expectation</title>
    <summary>  We design efficient approximation algorithms for maximizing the expectation
of the supremum of families of Gaussian random variables. In particular, let
$\mathrm{OPT}:=\max_{\sigma_1,\cdots,\sigma_n}\mathbb{E}\left[\sum_{j=1}^{m}\max_{i\in
S_j} X_i\right]$, where $X_i$ are Gaussian, $S_j\subset[n]$ and
$\sum_i\sigma_i^2=1$, then our theoretical results include:
  - We characterize the optimal variance allocation -- it concentrates on a
small subset of variables as $|S_j|$ increases,
  - A polynomial time approximation scheme (PTAS) for computing $\mathrm{OPT}$
when $m=1$, and
  - An $O(\log n)$ approximation algorithm for computing $\mathrm{OPT}$ for
general $m&gt;1$.
  Such expectation maximization problems occur in diverse applications, ranging
from utility maximization in auctions markets to learning mixture models in
quantitative genetics.
</summary>
    <author>
      <name>Renato Purita Paes Leme</name>
    </author>
    <author>
      <name>Cliff Stein</name>
    </author>
    <author>
      <name>Yifeng Teng</name>
    </author>
    <author>
      <name>Pratik Worah</name>
    </author>
    <link href="http://arxiv.org/abs/2502.18463v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.18463v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="stat.ML" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.18462v1</id>
    <updated>2025-02-25T18:59:13Z</updated>
    <published>2025-02-25T18:59:13Z</published>
    <title>Scalable Equilibrium Sampling with Sequential Boltzmann Generators</title>
    <summary>  Scalable sampling of molecular states in thermodynamic equilibrium is a
long-standing challenge in statistical physics. Boltzmann generators tackle
this problem by pairing powerful normalizing flows with importance sampling to
obtain statistically independent samples under the target distribution. In this
paper, we extend the Boltzmann generator framework and introduce Sequential
Boltzmann generators (SBG) with two key improvements. The first is a highly
efficient non-equivariant Transformer-based normalizing flow operating directly
on all-atom Cartesian coordinates. In contrast to equivariant continuous flows
of prior methods, we leverage exactly invertible non-equivariant architectures
which are highly efficient both during sample generation and likelihood
computation. As a result, this unlocks more sophisticated inference strategies
beyond standard importance sampling. More precisely, as a second key
improvement we perform inference-time scaling of flow samples using annealed
Langevin dynamics which transports samples toward the target distribution
leading to lower variance (annealed) importance weights which enable higher
fidelity resampling with sequential Monte Carlo. SBG achieves state-of-the-art
performance w.r.t. all metrics on molecular systems, demonstrating the first
equilibrium sampling in Cartesian coordinates of tri, tetra, and hexapeptides
that were so far intractable for prior Boltzmann generators.
</summary>
    <author>
      <name>Charlie B. Tan</name>
    </author>
    <author>
      <name>Avishek Joey Bose</name>
    </author>
    <author>
      <name>Chen Lin</name>
    </author>
    <author>
      <name>Leon Klein</name>
    </author>
    <author>
      <name>Michael M. Bronstein</name>
    </author>
    <author>
      <name>Alexander Tong</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Preprint</arxiv:comment>
    <link href="http://arxiv.org/abs/2502.18462v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.18462v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.18461v1</id>
    <updated>2025-02-25T18:59:12Z</updated>
    <published>2025-02-25T18:59:12Z</published>
    <title>K-LoRA: Unlocking Training-Free Fusion of Any Subject and Style LoRAs</title>
    <summary>  Recent studies have explored combining different LoRAs to jointly generate
learned style and content. However, existing methods either fail to effectively
preserve both the original subject and style simultaneously or require
additional training. In this paper, we argue that the intrinsic properties of
LoRA can effectively guide diffusion models in merging learned subject and
style. Building on this insight, we propose K-LoRA, a simple yet effective
training-free LoRA fusion approach. In each attention layer, K-LoRA compares
the Top-K elements in each LoRA to be fused, determining which LoRA to select
for optimal fusion. This selection mechanism ensures that the most
representative features of both subject and style are retained during the
fusion process, effectively balancing their contributions. Experimental results
demonstrate that the proposed method effectively integrates the subject and
style information learned by the original LoRAs, outperforming state-of-the-art
training-based approaches in both qualitative and quantitative results.
</summary>
    <author>
      <name>Ziheng Ouyang</name>
    </author>
    <author>
      <name>Zhen Li</name>
    </author>
    <author>
      <name>Qibin Hou</name>
    </author>
    <link href="http://arxiv.org/abs/2502.18461v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.18461v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2502.18460v1</id>
    <updated>2025-02-25T18:59:07Z</updated>
    <published>2025-02-25T18:59:07Z</published>
    <title>DRAMA: Diverse Augmentation from Large Language Models to Smaller Dense
  Retrievers</title>
    <summary>  Large language models (LLMs) have demonstrated strong effectiveness and
robustness while fine-tuned as dense retrievers. However, their large parameter
size brings significant inference time computational challenges, including high
encoding costs for large-scale corpora and increased query latency, limiting
their practical deployment. While smaller retrievers offer better efficiency,
they often fail to generalize effectively with limited supervised fine-tuning
data. In this work, we introduce DRAMA, a training framework that leverages
LLMs to train smaller generalizable dense retrievers. In particular, we adopt
pruned LLMs as the backbone and train on diverse LLM-augmented data in a
single-stage contrastive learning setup. Experiments show that DRAMA offers
better multilingual and long-context capabilities than traditional
encoder-based retrievers, and achieves strong performance across multiple tasks
and languages. These highlight the potential of connecting the training of
smaller retrievers with the growing advancements in LLMs, bridging the gap
between efficiency and generalization.
</summary>
    <author>
      <name>Xueguang Ma</name>
    </author>
    <author>
      <name>Xi Victoria Lin</name>
    </author>
    <author>
      <name>Barlas Oguz</name>
    </author>
    <author>
      <name>Jimmy Lin</name>
    </author>
    <author>
      <name>Wen-tau Yih</name>
    </author>
    <author>
      <name>Xilun Chen</name>
    </author>
    <link href="http://arxiv.org/abs/2502.18460v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2502.18460v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IR" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
