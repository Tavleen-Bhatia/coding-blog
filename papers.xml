<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Adeep%20learning%26id_list%3D%26start%3D0%26max_results%3D5" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:deep learning&amp;id_list=&amp;start=0&amp;max_results=5</title>
  <id>http://arxiv.org/api/o6m5I8YDMO+W1ZfiBhSOoh9xyHo</id>
  <updated>2025-05-19T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">425470</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">5</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2505.11494v1</id>
    <updated>2025-05-16T17:57:03Z</updated>
    <published>2025-05-16T17:57:03Z</published>
    <title>SHIELD: Safety on Humanoids via CBFs In Expectation on Learned Dynamics</title>
    <summary>  Robot learning has produced remarkably effective ``black-box'' controllers
for complex tasks such as dynamic locomotion on humanoids. Yet ensuring dynamic
safety, i.e., constraint satisfaction, remains challenging for such policies.
Reinforcement learning (RL) embeds constraints heuristically through reward
engineering, and adding or modifying constraints requires retraining.
Model-based approaches, like control barrier functions (CBFs), enable runtime
constraint specification with formal guarantees but require accurate dynamics
models. This paper presents SHIELD, a layered safety framework that bridges
this gap by: (1) training a generative, stochastic dynamics residual model
using real-world data from hardware rollouts of the nominal controller,
capturing system behavior and uncertainties; and (2) adding a safety layer on
top of the nominal (learned locomotion) controller that leverages this model
via a stochastic discrete-time CBF formulation enforcing safety constraints in
probability. The result is a minimally-invasive safety layer that can be added
to the existing autonomy stack to give probabilistic guarantees of safety that
balance risk and performance. In hardware experiments on an Unitree G1
humanoid, SHIELD enables safe navigation (obstacle avoidance) through varied
indoor and outdoor environments using a nominal (unknown) RL controller and
onboard perception.
</summary>
    <author>
      <name>Lizhi Yang</name>
    </author>
    <author>
      <name>Blake Werner</name>
    </author>
    <author>
      <name>Ryan K. Cosner</name>
    </author>
    <author>
      <name>David Fridovich-Keil</name>
    </author>
    <author>
      <name>Preston Culbertson</name>
    </author>
    <author>
      <name>Aaron D. Ames</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">Video at https://vimeo.com/1061676063</arxiv:comment>
    <link href="http://arxiv.org/abs/2505.11494v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.11494v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.11491v1</id>
    <updated>2025-05-16T17:55:06Z</updated>
    <published>2025-05-16T17:55:06Z</published>
    <title>Potential failures of physics-informed machine learning in traffic flow
  modeling: theoretical and experimental analysis</title>
    <summary>  This study critically examines the performance of physics-informed machine
learning (PIML) approaches for traffic flow modeling, defining the failure of a
PIML model as the scenario where it underperforms both its purely data-driven
and purely physics-based counterparts. We analyze the loss landscape by
perturbing trained models along the principal eigenvectors of the Hessian
matrix and evaluating corresponding loss values. Our results suggest that
physics residuals in PIML do not inherently hinder optimization, contrary to a
commonly assumed failure cause. Instead, successful parameter updates require
both ML and physics gradients to form acute angles with the quasi-true gradient
and lie within a conical region. Given inaccuracies in both the physics models
and the training data, satisfying this condition is often difficult.
Experiments reveal that physical residuals can degrade the performance of LWR-
and ARZ-based PIML models, especially under highly physics-driven settings.
Moreover, sparse sampling and the use of temporally averaged traffic data can
produce misleadingly small physics residuals that fail to capture actual
physical dynamics, contributing to model failure. We also identify the
Courant-Friedrichs-Lewy (CFL) condition as a key indicator of dataset
suitability for PIML, where successful applications consistently adhere to this
criterion. Lastly, we observe that higher-order models like ARZ tend to have
larger error lower bounds than lower-order models like LWR, which is consistent
with the experimental findings of existing studies.
</summary>
    <author>
      <name>Yuan-Zheng Lei</name>
    </author>
    <author>
      <name>Yaobang Gong</name>
    </author>
    <author>
      <name>Dianwei Chen</name>
    </author>
    <author>
      <name>Yao Cheng</name>
    </author>
    <author>
      <name>Xianfeng Terry Yang</name>
    </author>
    <link href="http://arxiv.org/abs/2505.11491v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.11491v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="physics.comp-ph" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.11484v1</id>
    <updated>2025-05-16T17:47:50Z</updated>
    <published>2025-05-16T17:47:50Z</published>
    <title>SoftCoT++: Test-Time Scaling with Soft Chain-of-Thought Reasoning</title>
    <summary>  Test-Time Scaling (TTS) refers to approaches that improve reasoning
performance by allocating extra computation during inference, without altering
the model's parameters. While existing TTS methods operate in a discrete token
space by generating more intermediate steps, recent studies in Coconut and
SoftCoT have demonstrated that thinking in the continuous latent space can
further enhance the reasoning performance. Such latent thoughts encode
informative thinking without the information loss associated with
autoregressive token generation, sparking increased interest in
continuous-space reasoning. Unlike discrete decoding, where repeated sampling
enables exploring diverse reasoning paths, latent representations in continuous
space are fixed for a given input, which limits diverse exploration, as all
decoded paths originate from the same latent thought. To overcome this
limitation, we introduce SoftCoT++ to extend SoftCoT to the Test-Time Scaling
paradigm by enabling diverse exploration of thinking paths. Specifically, we
perturb latent thoughts via multiple specialized initial tokens and apply
contrastive learning to promote diversity among soft thought representations.
Experiments across five reasoning benchmarks and two distinct LLM architectures
demonstrate that SoftCoT++ significantly boosts SoftCoT and also outperforms
SoftCoT with self-consistency scaling. Moreover, it shows strong compatibility
with conventional scaling techniques such as self-consistency. Source code is
available at https://github.com/xuyige/SoftCoT.
</summary>
    <author>
      <name>Yige Xu</name>
    </author>
    <author>
      <name>Xu Guo</name>
    </author>
    <author>
      <name>Zhiwei Zeng</name>
    </author>
    <author>
      <name>Chunyan Miao</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">14 pages</arxiv:comment>
    <link href="http://arxiv.org/abs/2505.11484v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.11484v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.11483v1</id>
    <updated>2025-05-16T17:47:15Z</updated>
    <published>2025-05-16T17:47:15Z</published>
    <title>msf-CNN: Patch-based Multi-Stage Fusion with Convolutional Neural
  Networks for TinyML</title>
    <summary>  AI spans from large language models to tiny models running on
microcontrollers (MCUs). Extremely memory-efficient model architectures are
decisive to fit within an MCU's tiny memory budget e.g., 128kB of RAM. However,
inference latency must remain small to fit real-time constraints. An approach
to tackle this is patch-based fusion, which aims to optimize data flows across
neural network layers. In this paper, we introduce msf-CNN, a novel technique
that efficiently finds optimal fusion settings for convolutional neural
networks (CNNs) by walking through the fusion solution space represented as a
directed acyclic graph. Compared to previous work on CNN fusion for MCUs,
msf-CNN identifies a wider set of solutions. We published an implementation of
msf-CNN running on various microcontrollers (ARM Cortex-M, RISC-V, ESP32). We
show that msf-CNN can achieve inference using 50% less RAM compared to the
prior art (MCUNetV2 and StreamNet). We thus demonstrate how msf-CNN offers
additional flexibility for system designers.
</summary>
    <author>
      <name>Zhaolan Huang</name>
    </author>
    <author>
      <name>Emmanuel Baccelli</name>
    </author>
    <link href="http://arxiv.org/abs/2505.11483v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.11483v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.11480v1</id>
    <updated>2025-05-16T17:40:45Z</updated>
    <published>2025-05-16T17:40:45Z</published>
    <title>Improving Assembly Code Performance with Large Language Models via
  Reinforcement Learning</title>
    <summary>  Large language models (LLMs) have demonstrated strong performance across a
wide range of programming tasks, yet their potential for code optimization
remains underexplored. This work investigates whether LLMs can optimize the
performance of assembly code, where fine-grained control over execution enables
improvements that are difficult to express in high-level languages. We present
a reinforcement learning framework that trains LLMs using Proximal Policy
Optimization (PPO), guided by a reward function that considers both functional
correctness, validated through test cases, and execution performance relative
to the industry-standard compiler gcc -O3. To support this study, we introduce
a benchmark of 8,072 real-world programs. Our model, Qwen2.5-Coder-7B-PPO,
achieves 96.0% test pass rates and an average speedup of 1.47x over the gcc -O3
baseline, outperforming all 20 other models evaluated, including
Claude-3.7-sonnet. These results indicate that reinforcement learning can
unlock the potential of LLMs to serve as effective optimizers for assembly code
performance.
</summary>
    <author>
      <name>Anjiang Wei</name>
    </author>
    <author>
      <name>Tarun Suresh</name>
    </author>
    <author>
      <name>Huanmi Tan</name>
    </author>
    <author>
      <name>Yinglun Xu</name>
    </author>
    <author>
      <name>Gagandeep Singh</name>
    </author>
    <author>
      <name>Ke Wang</name>
    </author>
    <author>
      <name>Alex Aiken</name>
    </author>
    <link href="http://arxiv.org/abs/2505.11480v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2505.11480v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PF" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.PL" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SE" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
