<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <link href="http://arxiv.org/api/query?search_query%3Dall%3Adeep%20learning%26id_list%3D%26start%3D0%26max_results%3D5" rel="self" type="application/atom+xml"/>
  <title type="html">ArXiv Query: search_query=all:deep learning&amp;id_list=&amp;start=0&amp;max_results=5</title>
  <id>http://arxiv.org/api/o6m5I8YDMO+W1ZfiBhSOoh9xyHo</id>
  <updated>2025-04-24T00:00:00-04:00</updated>
  <opensearch:totalResults xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">420619</opensearch:totalResults>
  <opensearch:startIndex xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">0</opensearch:startIndex>
  <opensearch:itemsPerPage xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/">5</opensearch:itemsPerPage>
  <entry>
    <id>http://arxiv.org/abs/2504.16929v1</id>
    <updated>2025-04-23T17:59:01Z</updated>
    <published>2025-04-23T17:59:01Z</published>
    <title>I-Con: A Unifying Framework for Representation Learning</title>
    <summary>  As the field of representation learning grows, there has been a proliferation
of different loss functions to solve different classes of problems. We
introduce a single information-theoretic equation that generalizes a large
collection of modern loss functions in machine learning. In particular, we
introduce a framework that shows that several broad classes of machine learning
methods are precisely minimizing an integrated KL divergence between two
conditional distributions: the supervisory and learned representations. This
viewpoint exposes a hidden information geometry underlying clustering, spectral
methods, dimensionality reduction, contrastive learning, and supervised
learning. This framework enables the development of new loss functions by
combining successful techniques from across the literature. We not only present
a wide array of proofs, connecting over 23 different approaches, but we also
leverage these theoretical results to create state-of-the-art unsupervised
image classifiers that achieve a +8% improvement over the prior
state-of-the-art on unsupervised classification on ImageNet-1K. We also
demonstrate that I-Con can be used to derive principled debiasing methods which
improve contrastive representation learners.
</summary>
    <author>
      <name>Shaden Alshammari</name>
    </author>
    <author>
      <name>John Hershey</name>
    </author>
    <author>
      <name>Axel Feldmann</name>
    </author>
    <author>
      <name>William T. Freeman</name>
    </author>
    <author>
      <name>Mark Hamilton</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">ICLR 2025; website: https://aka.ms/i-con . Proceedings of the
  Thirteenth International Conference on Learning Representations (ICLR 2025)</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.16929v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16929v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.IT" scheme="http://arxiv.org/schemas/atom"/>
    <category term="math.IT" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.16925v1</id>
    <updated>2025-04-23T17:53:34Z</updated>
    <published>2025-04-23T17:53:34Z</published>
    <title>Latent Diffusion Planning for Imitation Learning</title>
    <summary>  Recent progress in imitation learning has been enabled by policy
architectures that scale to complex visuomotor tasks, multimodal distributions,
and large datasets. However, these methods often rely on learning from large
amount of expert demonstrations. To address these shortcomings, we propose
Latent Diffusion Planning (LDP), a modular approach consisting of a planner
which can leverage action-free demonstrations, and an inverse dynamics model
which can leverage suboptimal data, that both operate over a learned latent
space. First, we learn a compact latent space through a variational
autoencoder, enabling effective forecasting of future states in image-based
domains. Then, we train a planner and an inverse dynamics model with diffusion
objectives. By separating planning from action prediction, LDP can benefit from
the denser supervision signals of suboptimal and action-free data. On simulated
visual robotic manipulation tasks, LDP outperforms state-of-the-art imitation
learning approaches, as they cannot leverage such additional data.
</summary>
    <author>
      <name>Amber Xie</name>
    </author>
    <author>
      <name>Oleh Rybkin</name>
    </author>
    <author>
      <name>Dorsa Sadigh</name>
    </author>
    <author>
      <name>Chelsea Finn</name>
    </author>
    <link href="http://arxiv.org/abs/2504.16925v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16925v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.16923v1</id>
    <updated>2025-04-23T17:51:36Z</updated>
    <published>2025-04-23T17:51:36Z</published>
    <title>Meta-Learning Online Dynamics Model Adaptation in Off-Road Autonomous
  Driving</title>
    <summary>  High-speed off-road autonomous driving presents unique challenges due to
complex, evolving terrain characteristics and the difficulty of accurately
modeling terrain-vehicle interactions. While dynamics models used in
model-based control can be learned from real-world data, they often struggle to
generalize to unseen terrain, making real-time adaptation essential. We propose
a novel framework that combines a Kalman filter-based online adaptation scheme
with meta-learned parameters to address these challenges. Offline meta-learning
optimizes the basis functions along which adaptation occurs, as well as the
adaptation parameters, while online adaptation dynamically adjusts the onboard
dynamics model in real time for model-based control. We validate our approach
through extensive experiments, including real-world testing on a full-scale
autonomous off-road vehicle, demonstrating that our method outperforms baseline
approaches in prediction accuracy, performance, and safety metrics,
particularly in safety-critical scenarios. Our results underscore the
effectiveness of meta-learned dynamics model adaptation, advancing the
development of reliable autonomous systems capable of navigating diverse and
unseen environments. Video is available at: https://youtu.be/cCKHHrDRQEA
</summary>
    <author>
      <name>Jacob Levy</name>
    </author>
    <author>
      <name>Jason Gibson</name>
    </author>
    <author>
      <name>Bogdan Vlahov</name>
    </author>
    <author>
      <name>Erica Tevere</name>
    </author>
    <author>
      <name>Evangelos Theodorou</name>
    </author>
    <author>
      <name>David Fridovich-Keil</name>
    </author>
    <author>
      <name>Patrick Spieler</name>
    </author>
    <link href="http://arxiv.org/abs/2504.16923v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16923v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.RO" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.SY" scheme="http://arxiv.org/schemas/atom"/>
    <category term="eess.SY" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.16922v1</id>
    <updated>2025-04-23T17:49:53Z</updated>
    <published>2025-04-23T17:49:53Z</published>
    <title>Generalized Neighborhood Attention: Multi-dimensional Sparse Attention
  at the Speed of Light</title>
    <summary>  Many sparse attention mechanisms such as Neighborhood Attention have
typically failed to consistently deliver speedup over the self attention
baseline. This is largely due to the level of complexity in attention
infrastructure, and the rapid evolution of AI hardware architecture. At the
same time, many state-of-the-art foundational models, particularly in computer
vision, are heavily bound by attention, and need reliable sparsity to escape
the O(n^2) complexity. In this paper, we study a class of promising sparse
attention mechanisms that focus on locality, and aim to develop a better
analytical model of their performance improvements. We first introduce
Generalized Neighborhood Attention (GNA), which can describe sliding window,
strided sliding window, and blocked attention. We then consider possible design
choices in implementing these approaches, and create a simulator that can
provide much more realistic speedup upper bounds for any given setting.
Finally, we implement GNA on top of a state-of-the-art fused multi-headed
attention (FMHA) kernel designed for the NVIDIA Blackwell architecture in
CUTLASS. Our implementation can fully realize the maximum speedup theoretically
possible in many perfectly block-sparse cases, and achieves an effective
utilization of 1.3 petaFLOPs/second in FP16. In addition, we plug various GNA
configurations into off-the-shelf generative models, such as Cosmos-7B,
HunyuanVideo, and FLUX, and show that it can deliver 28% to 46% end-to-end
speedup on B200 without any fine-tuning. We will open source our simulator and
Blackwell kernels directly through the NATTEN project.
</summary>
    <author>
      <name>Ali Hassani</name>
    </author>
    <author>
      <name>Fengzhe Zhou</name>
    </author>
    <author>
      <name>Aditya Kane</name>
    </author>
    <author>
      <name>Jiannan Huang</name>
    </author>
    <author>
      <name>Chieh-Yun Chen</name>
    </author>
    <author>
      <name>Min Shi</name>
    </author>
    <author>
      <name>Steven Walton</name>
    </author>
    <author>
      <name>Markus Hoehnerbach</name>
    </author>
    <author>
      <name>Vijay Thakkar</name>
    </author>
    <author>
      <name>Michael Isaev</name>
    </author>
    <author>
      <name>Qinsheng Zhang</name>
    </author>
    <author>
      <name>Bing Xu</name>
    </author>
    <author>
      <name>Haicheng Wu</name>
    </author>
    <author>
      <name>Wen-mei Hwu</name>
    </author>
    <author>
      <name>Ming-Yu Liu</name>
    </author>
    <author>
      <name>Humphrey Shi</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">https://github.com/SHI-Labs/NATTEN/</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.16922v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16922v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.LG" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2504.16920v1</id>
    <updated>2025-04-23T17:45:42Z</updated>
    <published>2025-04-23T17:45:42Z</published>
    <title>Summary statistics of learning link changing neural representations to
  behavior</title>
    <summary>  How can we make sense of large-scale recordings of neural activity across
learning? Theories of neural network learning with their origins in statistical
physics offer a potential answer: for a given task, there are often a small set
of summary statistics that are sufficient to predict performance as the network
learns. Here, we review recent advances in how summary statistics can be used
to build theoretical understanding of neural network learning. We then argue
for how this perspective can inform the analysis of neural data, enabling
better understanding of learning in biological and artificial neural networks.
</summary>
    <author>
      <name>Jacob A. Zavatone-Veth</name>
    </author>
    <author>
      <name>Blake Bordelon</name>
    </author>
    <author>
      <name>Cengiz Pehlevan</name>
    </author>
    <arxiv:comment xmlns:arxiv="http://arxiv.org/schemas/atom">11 pages, 2 figures</arxiv:comment>
    <link href="http://arxiv.org/abs/2504.16920v1" rel="alternate" type="text/html"/>
    <link title="pdf" href="http://arxiv.org/pdf/2504.16920v1" rel="related" type="application/pdf"/>
    <arxiv:primary_category xmlns:arxiv="http://arxiv.org/schemas/atom" term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
    <category term="q-bio.NC" scheme="http://arxiv.org/schemas/atom"/>
  </entry>
</feed>
